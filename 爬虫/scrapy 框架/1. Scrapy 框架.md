#### Scrapy 框架

- Scrapy是用纯Python实现一个为了爬取网站数据、提取结构性数据而编写的应用框架，用途非常广泛。 
- 框架的力量，用户只需要定制开发几个模块就可以轻松的实现一个爬虫，用来抓取网页内容以及各种图片，非常之方便。 
- Scrapy 使用了 Twisted (其主要对手是Tornado)异步网络框架来处理网络通讯，可以加快我们的下载速度，不用自己去实现异步框架，并且包含了各种中间件接口，可以灵活的完成各种需求。

 #### Scrapy 架构图

![](../asset/scrapy架构.png)



#### 基本使用

##### 一、新建项目

- 在开始爬取之前，必须创建一个新的Scrapy项目。进入自定义的项目目录中，运行下列命令：

```python
# 使用这个命令创建一个项目
scrapy startproject mySpider
# 其中， mySpider 为项目名称，可以看到将会创建一个 mySpider 文件夹
```

下面来简单介绍一下各个主要文件的作用：

> scrapy.cfg ：项目的配置文件
>
> mySpider/ ：项目的Python模块，将会从这里引用代码
>
> mySpider/items.py ：项目的目标文件
>
> mySpider/pipelines.py ：项目的管道文件
>
> mySpider/settings.py ：项目的设置文件
>
> mySpider/spiders/ ：存储爬虫代码目录



##### 二、明确目标（mySpider/items.py）

1. 打开mySpider目录下的items.py
2. Item 定义结构化数据字段，用来保存爬取到的数据，有点像Python中的dict，但是提供了一些额外的保护减少错误。
3. 可以通过创建一个 scrapy.Item 类， 并且定义类型为 scrapy.Field的类属性来定义一个Item（可以理解成类似于ORM的映射关系）。
4. 接下来，创建一个ItcastItem 类，和构建item模型（model）。 

```python
import scrapy

class ItcastItem(scrapy.Item):
    name = scrapy.Field()
    level = scrapy.Field()
    info = scrapy.Field()
```

##### 三、制作爬虫

- 在当前目录下输入命令，将在`mySpider/spider`目录下创建一个名为`itcast`的爬虫，并指定爬取域的范围：

```python
# 这里指定了爬虫名称 以及爬取的范围
scrapy genspider itcast "itcast.cn"
```

##### 四、保存数据（管道）

==需要到setting里开启管道==

```python
# 在项目中 指定启用哪些 管道
ITEM_PIPELINES = {
    'scrapy01.pipelines.ImagePip': 300,
}
```



##### 快速启动

编写 start.py 文件 里面的内容为

```python
from scrapy import cmdline
cmdline.execute("scrapy crawl qidian_spider".split())


from scrapy.cmdline import execute
execute(['scrapy', 'crawl', 'imgScrapy'])
```

