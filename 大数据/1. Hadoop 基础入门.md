#### Hadoop 2.x 介绍

---

Apache Hadoop 是一个开源软件框架，可安装在一个商用机器集群中，使机器可彼此通信并协同工作，以高度分布式的方式共同存储和处理大量数据。

##### Hadoop 1.x 概览

最初，Hadoop 包含以下两个主要组件：Hadoop Distributed File System (HDFS) 和一个分布式计算引擎，该引擎支持以 MapReduce 作业的形式实现和运行程序。  

> Hadoop 1.x 架构图

![](图片资料\20160114135449075.png)

> Hadoop Distributed File System (HDFS)  （Hadoop 1.x ）

![](图片资料\20170717212324040.png)

==上面的图有问题==

- 在 Hadoop 1.x 中没有 `Active namenode` 和  `standby namenode` 之分，而是 `namecode` 和 

  `second namecode`



####  HDFS 原理

- 一个文件被分成多个 block 块，Hadoop 1.x 64MB，Hadoop 2.x 128MB  ，大小都可以自定义
- block 块被存放在不同的 `DataNode` 上，

> ##### `NameNode` 详解

`NameNode` 是整个文件系统的管理节点，也是HDFS中最复杂的一个实体

- 用来接受客户端的读写服务
- 用来接受来自 `DataNode` 的数据块信息（当前 `DataNode` 里有哪些 `block` 块）

`NameNode` 上存放着文件的元信息 ( metadata )

==按类型分类==

- 文件和目录本身的原始信息，文件名，创建时间，等等
- 文件记录的信息的存储相关的信息，例如存储块信息，分块情况，副本个数等。 
- 记录 HDFS 的 `DataNode` 的信息，用于 `DataNode` 的管理 ( 每个 block 块，对应着哪个 `DataNode` )

==按存储位置分类 分为内存元数据和元数据文件（磁盘）两种==

- 存在磁盘上，用于持久化

  文件和目录本身的原始信息，文件名，创建时间，等等

  文件记录的信息的存储相关的信息，例如存储块信息，分块情况，副本个数等。 

- 存在内存当中，会动态更新

  `DataNode`会一直向 `NameNode` 发送心跳，里面会包含 block 块和 `DataNode` 对应的映射信息

  记录 HDFS 的 `DataNode` 的信息，用于 `DataNode` 的管理 ( 每个 block 块，对应着哪个 `DataNode` )

==元数据文件 fsimage 镜像文件==

fsimage 是元数据持久化生成的一个文件，里面包含了文件本身的原始信息，文件名等，以及存储相关的信息，分块情况等等，里面没有 block 块和 DataNode 映射信息

fsimage 是由 SecondNameNode 生成的，每隔一段时间会将 fsimage 和 edits 日志合并（包含了所有操作，修改添加等等）合并后，SecondNameNode 就把新的 fsimage 给 NameNode 。

这里需要把 edits 合并的原因是，在序列化的过程中，又会有新的文件操作，所以需要合并，然后生成新的 fsimage ，最后再推送给 NameNode 

==文件操作日志文件 edits==

当客户端对 HDFS 中的文件进行新增或者修改操作，操作记录首先被记入 edits 日志文 件中，当客户端操作成功后，相应的元数据会更新到内存元数据中。因为 fsimage 文件一般 都很大（GB 级别的很常见），如果所有的更新操作都往 fsimage 文件中添加，这样会导致系 统运行的十分缓慢。 

==启动==

每次 HDFS 启动的时候，都会把 fsimage 里面的数据导入内存，然后再根据 edits 里面的数据更新内存中的数据



> #### Secondary NameNode

定期合并 fsimage 和 edits 日志，将 edits 日志文件大小控制在一个限度下。  

- 可以设置合并的时间间隔
- 可以设置 edits 文件的阈值

---

#### Hadoop 2.x 概览

![](图片资料\204677-20160105160806778-688214909.png)

- Hadoop 2.x 和 Hadoop 1.x 相比主要多了 Yarn 层，MapReduce 在 Yarn 之上





