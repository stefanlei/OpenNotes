### HBase Shell 命令

##### 通过 `hbase shell` 命令进入 Hbase 命令行接口

==一个 RowKey 就是一条记录==

```python
# 创建表
create '表名','列族名'
create 'users','CF'

# 查看表详情
describe '表名'

# 添加记录  
put '表名','RowKey','列族名称：列名','值'
put 'users','1','CF:name','stefan'
put 'users','1','CF:age','stefan'

# 统计总记录数
count '表名'
count 'user'

# 删除记录  删除的时候需要指定到列名，不能直接删除一个族
delete '表名','RowKey','列族名：列名'

# 删除一张表 ，删除表之前，需要 disable 'table_name'
drop '表名'
drop 'user'

# 查询所有的记录
scan 'user'

# disable 禁用表
disable users

# 启用表
disable users
```

> 查询操作

```sh
# 查看记录 
get '表名','Rowkey','列族名称:列名',
get 'user','1','CF:name'
get 'user'

# 限制记录
scan 'user',{LIMIT=>2}

# 查询条件  rowkey 以 row1 开头
scan 'user',{STARTROW=>'row1'}

# row 以 123 结尾
scan 'user',{ENDROW=>'123'}
```



---



#### Python happybase

[参考链接](https://blog.csdn.net/y472360651/article/details/79059457)

需要在服务器上开启 `thrift`

`hbase thrift -p 9090 start`



==需要安装 happybase==`pip3 install happybase`

如果后面运行的时候报错了

`thriftpy.parser.exc.ThriftParserError: ThriftPy does not support generating module with path in protocol 'c'`

```
将 Python 安装目录下的 
\Lib\site-packages\thriftpy\parser\parser.py , line 488  

if url_scheme == '':
修改为
if len(url_scheme) <= 1:

```

> 查询

```python
import happybase

# 这里是建立一个连接
connection = happybase.Connection(host='hadoop1', autoconnect=True)
# 创建表
# connection.create_table('students', {'cf': dict()})

# 查询有哪些表
print(connection.tables())

# 获取表对象
users = connection.table('users')

# 查询表里面所有的数据
print(list(users.scan()))

# 查询指定行中所有数据 RowKey
print(users.row('1'))

# 查询指定行中,指定的列族
print(users.row('1', ['cf']))

# 查询指定行中,指定的列族，指定的列
print(users.row('1', ['cf:name']))

# 显示所有的列族 包含列族名称和其他相关信息
print(users.families())

# 同时查询多行
rows = users.rows(['1', 'aaaa'])
for key, data in rows:
    print(key, data)
    
    
# 查询具体的数据 可以指定版号数量
print(users.cells('001', column='cf:name', versions=1))
```

> 添加

```python
import happybase

connection = happybase.Connection(host='hadoop1', autoconnect=True)

# 创建表的时候，就已经确定了可以插入什么列名
# connection.create_table('users', {'info': dict()})
users = connection.table('users')

# 要添加的数据
user1 = {
    'info:name': 'stefan',
    'info:age': '20',
    'info:address': 'NanChang'
}

# 把数据插入到指定的row中去
users.put(row='001', data=user1)
```

> 删除

```python
import happybase

connection = happybase.Connection(host='hadoop1', autoconnect=True)

# connection.create_table('users', {'info': dict()})
users = connection.table('users')
#
# 要添加的数据
data1 = {
    'info:name': 'stefan',
    'info:age': '20',
    'info:address': 'NanChang',
}

# 把数据插入到指定的row中去
users.put(row='001', data=data1)

# 删除整条数据
users.delete(row='001')
#
# 删除特定的列族
users.delete(row='001', columns=['likes'])
#
# 删除特定的列
users.delete(row='001', columns=['info:age'])

```

> 操作表

```python
import happybase
connection = happybase.Connection(host='hadoop1', autoconnect=True)

# 删除表 name 表名， disable 是否先禁用表
connection.delete_table(name, disable=False)

# 禁用表
connection.disable_table(name)

# 启用表
connection.enable_table(name)
```

> 表的批量操作

```python
import happybase

connection = happybase.Connection(host='hadoop1', autoconnect=True)

users = connection.table('users')

# 使用  batch 来批量操作，也可以批量删除
users_bt = users.batch()
users_bt.put('001', data={
    'cf:name': 'stefan',
    'cf:age': '18'
})
users_bt.put('002', data={
    'cf:name': 'damon',
    'cf:age': '19'
})

# 这里相当于提交事务
users_bt.send()
```

>  使用 cells 查询数据

==查询到具体的值，结果不包含键==

```python
# 这样就可以查到具体的 name
print(table.cells('users', 'cf1:name', include_timestamp=True))
```

> 过滤查询

==针对 users.scan()==

```python
# row_start row_stop ，查询两者之间的数据 左闭右开

# 查询 001 以后的数据 (包含 001)
users.scan(row_start='001')
# 查询 002 之前的数据 （不包含 002)
users.scan(row_stop='002')
```

```python
# row_prefix，查询以 row_prefix 为前缀的数据,不能和 row_start,row_stop 同时使用

import happybase
connection = happybase.Connection(host='hadoop1', autoconnect=True)
tables = connection.tables()
users = connection.table('users')
# 查询以 001 开头的数据
print(list(users.scan(row_prefix=b'001')))
```

```python
# filter：要使用的过滤器(hbase 0.92版本及以上生效)
# timestamp：按指定时间戳查询
# reverse：默认为False。为True时，scan结果按rowkey倒序排列

# scan(self, row_start=None, row_stop=None, row_prefix=None,
#              columns=None, filter=None, timestamp=None,
#              include_timestamp=False, batch_size=1000, scan_batching=None,
#              limit=None, sorted_columns=False, reverse=False)
```

